import json
from typing import Optional, List
import time
import logging
logging.getLogger("snowflake.connector").setLevel(logging.FATAL)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
from snowflake.snowpark import Session
import re
from snowflake.core import Root
from snowflakeray.deploy_client.image_builds import docker_context
from snowflake.core.compute_pool import ComputePool
from snowflake.core.service import Service
from snowflakeray.deploy_client.snowservice.deploy import (
    _get_or_create_image_repo,
    _get_full_image_name,
    _build_and_upload_image,
    _delete_image_repo
)
import bisect
from snowflakeray.deploy_client.image_registry import registry_client as image_registry_client
from snowflakeray.deploy_client.utils import constants
import importlib_resources
from snowflakeray.deploy_client.utils.constants import RAY_HEAD_SPEC_TEMPLATE, RAY_WORKER_SPEC_TEMPLATE, RAY_HEAD_SPEC_OUTPUT, RAY_WORKER_SPEC_OUTPUT, RAY_BASE_IMAGE_NAME_IN_IMAGE_REPO, RAY_GRAFANA_IMAGE_NAME_IN_IMAGE_REPO, RAY_PROMETHEUS_IMAGE_NAME_IN_IMAGE_REPO, GPU_COMPUTE_POOL_LIST, GPU_COMPUTE_POOL_MAPPING, GPU_COMPUTE_POOL_CORES_MAPPING, RAY_IMAGE_REPO_NAME, HIGH_MEMORY_COMPUTE_POOL_CORES_LIST, CPU_COMPUTE_POOL_CORES_MAPPING, CPU_COMPUTE_POOL_CORES_LIST, HIGH_MEMORY_COMPUTE_POOL_CORES_MAPPING, RayImageType, RAY_HEAD_IMAGE_NAME_IN_IMAGE_REPO, RAY_WORKER_IMAGE_NAME_IN_IMAGE_REPO, UI_PORTS, INSTANCE_AVAILABLE_MEMORY_FOR_RAY_FACTOR, DHSM_MEMORY_FACTOR, COMPUTE_POOL_MEMORY_MAPPING, COMPUTE_POOL_MEMORY_MAPPING, RAY_HEAD_CONTAINER_NAME, RAY_WORKER_CONTAINER_NAME, RAY_HEAD_SERVICE_NAME, RAY_GRAFANA_CONTAINER_NAME, RAY_PROMETHEUS_CONTAINER_NAME, RAY_HEAD_COMPUTE_POOL_NAME, RAY_WORKER_COMPUTE_POOL_NAME, RAY_HEAD_SERVICE_NAME, RAY_HEAD_SPEC_OUTPUT, RAY_WORKER_SERVICE_NAME, RAY_LOGS_REGULAR_STORAGE_NAME, BLOCK_STORAGE_NAME, DEFAULT_BLOCK_STORAGE_SIZE_FOR_RAY_LOGS, ResourceType, SNOW_OBJECT_IDENTIFIER_MAX_LENGTH, INSTANCE_TYPE_MAPPING, GPU_CONSTANT, CPU_CONSTANT, COMPUTE_POOL_CORES_MAPPING, COMPUTE_POOL_GPU_MAPPING, HIGH_MEM_CONSTANT, MIN_DSHM_MEMORY
from snowflakeray.docker_context_dir.specs import templates
from snowflakeray.docker_context_dir import ray_base as ray_base_docker_context_dir
from snowflakeray.docker_context_dir import ray_head as ray_head_docker_context_dir
from snowflakeray.docker_context_dir import ray_worker as ray_worker_docker_context_dir
from snowflakeray.docker_context_dir import grafana as grafana_context_dir
from snowflakeray.docker_context_dir import prometheus as prometheus_context_dir
from snowflakeray.docker_context_dir.specs import autogenerated as autogenerated_specs_dir
import string
import os
import os
import yaml
import numpy as np
from snowflakeray.deploy_client.utils import file_utils
from snowflakeray.deploy_client.utils.snowservice_client import SnowServiceClient
class InternalSPCSRayCluster():
    def __init__(self, session:Session, project_name:str, head_compute_pool_name:str, worker_compute_pool_name:str) -> None:
        self.image_repo_name = None
        self.context_dir_ray_base = os.path.dirname(ray_base_docker_context_dir.__file__)
        self.context_dir_ray_head = os.path.dirname(ray_head_docker_context_dir.__file__)
        self.context_dir_ray_worker = os.path.dirname(ray_worker_docker_context_dir.__file__)
        self.context_dir_grafana = os.path.dirname(grafana_context_dir.__file__)
        self.context_dir_prometheus = os.path.dirname(prometheus_context_dir.__file__)
        self.spec_output_dir = os.path.dirname(autogenerated_specs_dir.__file__)
        self.session = session
        self.project_name_clean = re.sub('[^0-9a-zA-Z]+', '', project_name).strip()
        self.database_name = self.session.get_current_database().replace("\"", "")
        self.schema_name = self.session.get_current_schema().replace("\"", "")
        self.database_name_clean = re.sub('[^0-9a-zA-Z]+', '', self.database_name).strip()
        self.schema_name_clean = re.sub('[^0-9a-zA-Z]+', '', self.schema_name).strip()
        self.root = Root(self.session)
        self.snow_serv_client = SnowServiceClient(session=self.session)
        self.ray_head_service_name = self.get_object_identifier_name(RAY_HEAD_SERVICE_NAME)
        self.ray_worker_service_name = self.get_object_identifier_name(RAY_WORKER_SERVICE_NAME)
        self.image_repo_name = self.get_object_identifier_name(RAY_IMAGE_REPO_NAME)
        self.ray_logs_regular_storage_name = self.get_object_identifier_name(RAY_LOGS_REGULAR_STORAGE_NAME)
        self.ray_head_precreated_compute_pool = False
        self.ray_worker_precreated_compute_pool = False
        if head_compute_pool_name is not None:
            self.ray_head_compute_pool_name = head_compute_pool_name.upper()
            self.ray_head_precreated_compute_pool = True
        else:    
            self.ray_head_compute_pool_name = self.get_object_identifier_name(RAY_HEAD_COMPUTE_POOL_NAME + "_" + self.database_name_clean)
        if worker_compute_pool_name is not None:
            self.ray_worker_compute_pool_name = worker_compute_pool_name.upper()
            self.ray_worker_precreated_compute_pool = True
        else:
            self.ray_worker_compute_pool_name = self.get_object_identifier_name(RAY_WORKER_COMPUTE_POOL_NAME + "_" + self.database_name_clean)
        
        
    def setup_ray_cluster(self, compute_pool_type:str, num_worker_nodes:int, stage_name_for_specs:str, stage_name_for_artifacts:str, requested_num_worker_gpus:Optional[int], requested_num_head_gpus:Optional[int], requested_num_head_cores:Optional[int], requested_num_worker_cores:Optional[int], pip_requirements:Optional[List], ray_requirements:Optional[List], force_image_build:Optional[bool]=False, external_access_integrations:Optional[List]=[], need_block_storage_for_ray_logs:Optional[bool]=False, query_warehouse:Optional[str]="")->dict:
        compute_pool_type = compute_pool_type.upper() #CPU, GPU, HIGH_MEM
        self.num_worker_nodes = num_worker_nodes
        self.compute_pool_type = compute_pool_type
        self.requested_num_worker_gpus = requested_num_worker_gpus
        self.requested_num_head_gpus = requested_num_head_gpus
        self.requested_num_head_cores = requested_num_head_cores
        self.requested_num_worker_cores = requested_num_worker_cores
        self.pip_requirements = pip_requirements
        self.ray_requirements = ray_requirements
        self.force_image_build = force_image_build
        self.external_access_integrations = external_access_integrations
        self.need_block_storage_for_ray_logs = need_block_storage_for_ray_logs
        self.stage_name_for_specs = self.get_object_identifier_name(stage_name_for_specs)
        self.stage_name_for_artifacts = self.get_object_identifier_name(stage_name_for_artifacts)
        self.query_warehouse = query_warehouse
        #validate and fix setup
        self.validate_and_fix_setup()
        if self.ray_head_precreated_compute_pool:
            [ray_head_instance_family, ray_head_min_nodes, ray_head_max_nodes, ray_head_compute_pool_type] = self.get_compute_pool_properties(self.ray_head_compute_pool_name)
            num_head_gpus = COMPUTE_POOL_GPU_MAPPING[ray_head_instance_family]
            num_head_cores = COMPUTE_POOL_CORES_MAPPING[ray_head_instance_family]
            self.ray_head_compute_pool_type = ray_head_compute_pool_type
            self.compute_pool_type = ray_head_compute_pool_type
        if self.ray_worker_precreated_compute_pool:
            [ray_worker_instance_family, ray_worker_min_nodes, ray_worker_max_nodes, ray_worker_compute_pool_type] = self.get_compute_pool_properties(self.ray_worker_compute_pool_name)
            num_worker_gpus = COMPUTE_POOL_GPU_MAPPING[ray_worker_instance_family]
            num_worker_cores = COMPUTE_POOL_CORES_MAPPING[ray_worker_instance_family]
            self.num_worker_nodes = ray_worker_min_nodes
            self.ray_worker_compute_pool_type = ray_worker_compute_pool_type
            self.compute_pool_type = ray_worker_compute_pool_type
        if not(self.ray_head_precreated_compute_pool and self.ray_worker_precreated_compute_pool):
            #get instance types
            [ray_head_instance_family, ray_worker_instance_family, num_head_gpus, num_worker_gpus, num_head_cores, num_worker_cores] = self.calculate_cores_and_instance_types()
            self.ray_head_compute_pool_type = self.compute_pool_type
            self.ray_worker_compute_pool_type = self.compute_pool_type
        self.image_repo = self.create_image_repo(self.image_repo_name)
        #build and upload images
        [full_image_name_ray_grafana, full_image_name_ray_prometheus, full_image_name_ray_base, full_image_name_ray_head, full_image_name_ray_worker] = self.build_and_upload_images()
        #create stages before bringing in specs
        self.create_stage_if_not_exists(stage_name=self.stage_name_for_artifacts, need_directory_enabled=True)
        self.create_stage_if_not_exists(stage_name=self.stage_name_for_specs)
        if not self.need_block_storage_for_ray_logs:
            self.create_stage_if_not_exists(stage_name=self.ray_logs_regular_storage_name)
        num_cores = num_worker_cores if num_worker_nodes > 0 else num_head_cores
        self.build_and_upload_specs(ray_head_instance_family=ray_head_instance_family, ray_worker_instance_family=ray_worker_instance_family, num_cores=num_cores, full_image_name_ray_head=full_image_name_ray_head, full_image_name_ray_prometheus=full_image_name_ray_prometheus, full_image_name_ray_grafana=full_image_name_ray_grafana, full_image_name_ray_worker=full_image_name_ray_worker, num_head_gpus=num_head_gpus, num_worker_gpus=num_worker_gpus)
        #create compute pools
        ray_head_compute_pool = self.get_or_create_compute_pool(self.ray_head_compute_pool_name, ray_head_instance_family, 1, 1, self.ray_head_service_name, "head")
        if self.num_worker_nodes > 0:
            ray_worker_compute_pool = self.get_or_create_compute_pool(self.ray_worker_compute_pool_name, ray_worker_instance_family, self.num_worker_nodes, self.num_worker_nodes, self.ray_worker_service_name, "worker")
        #create or replace services
        self.snow_serv_client.create_or_replace_service(
            service_name=self.ray_head_service_name,
            min_instances=1,
            max_instances=1,
            compute_pool=self.ray_head_compute_pool_name,
            spec_stage_location=f"@{self.stage_name_for_specs}",
            spec_file_name=RAY_HEAD_SPEC_OUTPUT,
            external_access_integrations=self.external_access_integrations,
            query_warehouse = self.query_warehouse
        )
        if self.num_worker_nodes > 0:
            self.snow_serv_client.create_or_replace_service(
                service_name=self.ray_worker_service_name,
                min_instances=self.num_worker_nodes,
                max_instances=self.num_worker_nodes,
                compute_pool=self.ray_worker_compute_pool_name,
                spec_stage_location=f"@{self.stage_name_for_specs}",
                spec_file_name=RAY_WORKER_SPEC_OUTPUT,
                external_access_integrations=self.external_access_integrations,
                query_warehouse = self.query_warehouse
            )
        self.snow_serv_client.block_until_resource_is_ready(resource_name=self.ray_head_service_name, resource_type=ResourceType.SERVICE, container_name=RAY_HEAD_CONTAINER_NAME)
        if self.num_worker_nodes > 0:
            self.snow_serv_client.block_until_resource_is_ready(resource_name=self.ray_worker_service_name, resource_type=ResourceType.SERVICE, container_name=RAY_WORKER_CONTAINER_NAME)
        ray_head_public_endpoints = self.get_public_endpoints_by_service_name(self.ray_head_service_name)
        return ray_head_public_endpoints
        
    
    def get_object_identifier_name(self, name:str):
        return str(name + self.project_name_clean).upper()[0:SNOW_OBJECT_IDENTIFIER_MAX_LENGTH-1]
        
    def validate_and_fix_setup(self):
        if self.compute_pool_type not in ['HIGH_MEM', 'CPU', 'GPU']:
            raise Exception("Invalid compute type. Must be one of CPU, GPU or HIGH_MEM")
        print(f"ray_head_precreated_compute_pool: {str(self.ray_head_precreated_compute_pool)}")
        print(f"ray_worker_precreated_compute_pool: {str(self.ray_worker_precreated_compute_pool)}")
        if not (self.ray_head_precreated_compute_pool and self.ray_worker_precreated_compute_pool):
            if self.compute_pool_type == 'GPU':
                if self.requested_num_head_gpus is None:
                    raise Exception("Since the selected compute pool type is GPU, please provide value for requested_num_head_gpus parameter")
                if self.num_worker_nodes >0 and self.requested_num_worker_gpus is None:
                    raise Exception("Since the selected compute pool type is GPU, please provide value for requested_num_worker_gpus parameter")    
            if self.compute_pool_type != 'GPU':
                if self.requested_num_head_cores is None:
                    raise Exception(f"Since the selected compute pool type is {self.compute_pool_type}, please provide value for requested_num_head_cores parameter")
                if self.num_worker_nodes > 0 and self.requested_num_worker_cores is None:
                    raise Exception(f"Since the selected compute pool type is {self.compute_pool_type} and num_worker_nodes>0, please provide value for requested_num_worker_cores parameter")
                    
        if self.pip_requirements is None or len(self.pip_requirements)==0:
            self.pip_requirements = ["jupyterlab", "pandas", "py-spy", "ipywidgets", "virtualenv", "starlette<=0.34.0"]
        if self.ray_requirements is None or len(self.ray_requirements)==0:
            self.ray_requirements = ["ray[data]==2.9.3", "ray[client]==2.9.3", "ray[default]==2.9.3", "ray[serve]==2.9.3"]
        if "@" in self.stage_name_for_specs:
            self.stage_name_for_specs = self.stage_name_for_specs.replace("@", "")
        if "@" in self.stage_name_for_artifacts:
            self.stage_name_for_artifacts = self.stage_name_for_artifacts.replace("@", "")
        if self.num_worker_nodes < 0:
            raise Exception("Number of worker nodes cannot be negative.")
            
        
        
    def calculate_cores_and_instance_types(self):
        num_head_gpus = None
        num_worker_gpus = None
        num_worker_cores = None
        num_head_cores = None
        ray_head_instance_family = None
        ray_worker_instance_family = None
        if self.compute_pool_type ==  GPU_CONSTANT:
            num_head_gpus = self.closest_bisect(GPU_COMPUTE_POOL_LIST, self.requested_num_head_gpus)
            if self.num_worker_nodes >0:
                num_worker_gpus = self.closest_bisect(GPU_COMPUTE_POOL_LIST, self.requested_num_worker_gpus)
            ray_head_instance_family = GPU_COMPUTE_POOL_MAPPING[num_head_gpus]
            if self.num_worker_nodes >0:
                ray_worker_instance_family = GPU_COMPUTE_POOL_MAPPING[num_worker_gpus]
            num_head_cores = GPU_COMPUTE_POOL_CORES_MAPPING[ray_head_instance_family]
            if self.num_worker_nodes >0:
                num_worker_cores = GPU_COMPUTE_POOL_CORES_MAPPING[ray_worker_instance_family]
        elif self.compute_pool_type == 'HIGH_MEM':
            num_head_cores = self.closest_bisect(HIGH_MEMORY_COMPUTE_POOL_CORES_LIST, self.requested_num_head_cores)
            if self.num_worker_nodes >0:
                num_worker_cores = self.closest_bisect(HIGH_MEMORY_COMPUTE_POOL_CORES_LIST, self.requested_num_worker_cores)
            ray_head_instance_family = HIGH_MEMORY_COMPUTE_POOL_CORES_MAPPING[num_head_cores]
            if self.num_worker_nodes >0:
                ray_worker_instance_family = HIGH_MEMORY_COMPUTE_POOL_CORES_MAPPING[num_worker_cores]
        elif self.compute_pool_type == CPU_CONSTANT:
            num_head_cores = self.closest_bisect(CPU_COMPUTE_POOL_CORES_LIST, self.requested_num_head_cores)
            if self.num_worker_nodes >0:
                num_worker_cores = self.closest_bisect(CPU_COMPUTE_POOL_CORES_LIST, self.requested_num_worker_cores)
            ray_head_instance_family = CPU_COMPUTE_POOL_CORES_MAPPING[num_head_cores]
            if self.num_worker_nodes >0:
                ray_worker_instance_family = CPU_COMPUTE_POOL_CORES_MAPPING[num_worker_cores]
        return [ray_head_instance_family, ray_worker_instance_family, num_head_gpus, num_worker_gpus, num_head_cores, num_worker_cores]
    
    def closest_bisect(self, lst, k):
        lst.sort()
        index = bisect.bisect_left(lst, k)
        if index == 0:
            closest = lst[0]
        elif index == len(lst):
            closest = lst[-1]
        else:
            before = lst[index-1]
            after = lst[index]
            closest = before if after-k > k-before else after
        return closest
    
    def create_image_repo(self, image_repo_name:str):
        image_repo = _get_or_create_image_repo(
                    session = self.session, image_repo_name=image_repo_name
                )
        logger.info(f"Created image repo: {image_repo}")
        return image_repo
    
    def build_and_upload_images(self):
        #Build docker context for ray base image
        dc = docker_context.DockerContext(
            context_dir=self.context_dir_ray_base,
            image_type = RayImageType.IMAGE_TYPE_BASE,
            compute_pool_type = self.compute_pool_type,
            pip_requirements=self.pip_requirements,
            ray_requirements=self.ray_requirements
        )
        dc.build()
        #Build and upload grafana
        self.build_and_upload_image(self.context_dir_grafana, RAY_GRAFANA_IMAGE_NAME_IN_IMAGE_REPO)
        #Build and upload prometheus
        self.build_and_upload_image(self.context_dir_prometheus, RAY_PROMETHEUS_IMAGE_NAME_IN_IMAGE_REPO)
        #Build and upload ray base
        self.build_and_upload_image(self.context_dir_ray_base, RAY_BASE_IMAGE_NAME_IN_IMAGE_REPO)
        full_image_name_ray_grafana = _get_full_image_name(image_repo=self.image_repo, image_name=RAY_GRAFANA_IMAGE_NAME_IN_IMAGE_REPO, context_dir=self.context_dir_grafana)
        full_image_name_ray_prometheus = _get_full_image_name(image_repo=self.image_repo, image_name=RAY_PROMETHEUS_IMAGE_NAME_IN_IMAGE_REPO, context_dir=self.context_dir_prometheus)
        full_image_name_ray_base = _get_full_image_name(image_repo=self.image_repo, image_name=RAY_BASE_IMAGE_NAME_IN_IMAGE_REPO, context_dir=self.context_dir_ray_base)
        #build docker context for ray head based on ray base
        dc = docker_context.DockerContext(
            context_dir=self.context_dir_ray_head,
            image_type = RayImageType.IMAGE_TYPE_HEAD,
            base_full_image_name=full_image_name_ray_base
        )
        dc.build()
        #Build and upload ray head
        self.build_and_upload_image(self.context_dir_ray_head, RAY_HEAD_IMAGE_NAME_IN_IMAGE_REPO)
        full_image_name_ray_head = _get_full_image_name(image_repo=self.image_repo, image_name=RAY_HEAD_IMAGE_NAME_IN_IMAGE_REPO, context_dir=self.context_dir_ray_head)
        full_image_name_ray_worker = None
        if self.num_worker_nodes>0:
            #build docker context for ray worker based on ray base
            dc = docker_context.DockerContext(
                context_dir=self.context_dir_ray_worker,
                image_type = RayImageType.IMAGE_TYPE_WORKER,
                base_full_image_name=full_image_name_ray_base
            )
            dc.build()
            #Build and upload ray worker
            self.build_and_upload_image(self.context_dir_ray_worker, RAY_WORKER_IMAGE_NAME_IN_IMAGE_REPO)
            full_image_name_ray_worker = _get_full_image_name(image_repo=self.image_repo, image_name=RAY_WORKER_IMAGE_NAME_IN_IMAGE_REPO, context_dir=self.context_dir_ray_worker)
        return [full_image_name_ray_grafana, full_image_name_ray_prometheus, full_image_name_ray_base, full_image_name_ray_head, full_image_name_ray_worker]
    
    def build_and_upload_image(self, docker_context_dir: str, image_name: str):
        full_image_name = _get_full_image_name(image_repo=self.image_repo, context_dir=docker_context_dir, image_name=image_name)
        registry_client = image_registry_client.ImageRegistryClient(self.session, full_image_name)
        if not self.force_image_build and registry_client.image_exists(full_image_name=full_image_name):
            logger.info(
                f"Similar environment detected. Using existing image {full_image_name} to skip image "
                f"build. To disable this feature, set 'force_image_build=True' in deployment options"
            )
        else:
            logger.info(
                "Building the Docker image and deploying to Snowpark Container Service. "
            )
            start = time.time()
            _build_and_upload_image(
                session=self.session, context_dir=docker_context_dir, image_repo=self.image_repo, full_image_name=full_image_name
            )
            end = time.time()
            logger.info(f"Time taken to build and upload image to registry: {end - start:.2f} seconds")
            logger.warning(
                f"Image successfully built! For future deployments, the image will be reused if "
                f"possible, saving deployment time."
            )
            
    def create_stage_if_not_exists(self, stage_name:str, need_directory_enabled:Optional[bool]=False):
        if need_directory_enabled:
            self.session.sql(f"create stage if not exists {stage_name} ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE') DIRECTORY = (ENABLE = TRUE)").collect()
        else:
            self.session.sql(f"create stage if not exists {stage_name} ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')").collect()
            
    def build_and_upload_specs(self, ray_head_instance_family:str, ray_worker_instance_family:str, num_cores:int, full_image_name_ray_head:str, full_image_name_ray_prometheus:str, full_image_name_ray_grafana:str, full_image_name_ray_worker:str, num_head_gpus:Optional[int]=0, num_worker_gpus:Optional[int]=0):
        ray_head_spec_template = (
                importlib_resources.files(templates)
                .joinpath(RAY_HEAD_SPEC_TEMPLATE)  # type: ignore[no-untyped-call]
                .read_text("utf-8")
            )
        ray_head_spec_file_output_path = os.path.join(
                self.spec_output_dir, f"{RAY_HEAD_SPEC_OUTPUT}"
            )
        
        instance_available_memory_for_ray_head = str(int(INSTANCE_AVAILABLE_MEMORY_FOR_RAY_FACTOR * COMPUTE_POOL_MEMORY_MAPPING[ray_head_instance_family])) + 'G'
        dshm = int(DHSM_MEMORY_FACTOR * COMPUTE_POOL_MEMORY_MAPPING[ray_head_instance_family])
        if dshm < MIN_DSHM_MEMORY:
            dshm = MIN_DSHM_MEMORY
        dshm_memory_for_ray_head = str(MIN_DSHM_MEMORY) + 'Gi'
        with file_utils.open_file(ray_head_spec_file_output_path, "w") as spec_file:
            substitutes = {
                            "ray_head_container_name": RAY_HEAD_CONTAINER_NAME,
                            "ray_head_full_image_name": full_image_name_ray_head,
                            "ray_head_service_name": self.ray_head_service_name,
                            "instance_available_memory_for_ray": instance_available_memory_for_ray_head,
                            "ray_prometheus_container_name": RAY_PROMETHEUS_CONTAINER_NAME,
                            "ray_prometheus_full_image_name": full_image_name_ray_prometheus,
                            "ray_grafana_container_name": RAY_GRAFANA_CONTAINER_NAME,
                            "ray_grafana_full_image_name": full_image_name_ray_grafana,
                            "dshm_memory": dshm_memory_for_ray_head ,
                            "artifacts_stage": f"@{self.stage_name_for_artifacts}",
                            "num_cpu_cores": num_cores,
                            "raylogssource": BLOCK_STORAGE_NAME if self.need_block_storage_for_ray_logs else f"@{self.ray_logs_regular_storage_name}",
                            "raylogssourcesize": f'size: {DEFAULT_BLOCK_STORAGE_SIZE_FOR_RAY_LOGS}' if self.need_block_storage_for_ray_logs else "" 
            }
            content = string.Template(ray_head_spec_template).substitute(substitutes)
            content_dict = yaml.safe_load(content)
            if self.ray_head_compute_pool_type == 'GPU':
                container = content_dict["spec"]["containers"][0]
                # TODO[shchen]: SNOW-871538, external dependency that only single GPU is supported on SnowService.
                # GPU limit has to be specified in order to trigger the workload to be run on GPU in SnowService.
                container["resources"] = {
                    "limits": {"nvidia.com/gpu": num_head_gpus},
                    "requests": {"nvidia.com/gpu": num_head_gpus},
                }
            yaml.dump(content_dict, spec_file, sort_keys=False)
            logger.debug("Create service spec: \n, %s", content_dict)
        #upload spec for ray head
        self.session.file.put(
            local_file_name=ray_head_spec_file_output_path,
            stage_location=f"@{self.stage_name_for_specs}",
            auto_compress=False,
            overwrite=True,
        )
        logger.info(
            f"Uploaded spec file {os.path.basename(ray_head_spec_file_output_path)} " f"to {self.stage_name_for_specs}"
        )
        if self.num_worker_nodes >0:
            ray_worker_spec_template = (
                    importlib_resources.files(templates)
                    .joinpath(RAY_WORKER_SPEC_TEMPLATE)  # type: ignore[no-untyped-call]
                    .read_text("utf-8")
                )
            ray_worker_spec_file_output_path = os.path.join(
                    self.spec_output_dir, f"{RAY_WORKER_SPEC_OUTPUT}"
                )
        
            instance_available_memory_for_ray_worker = str(int(INSTANCE_AVAILABLE_MEMORY_FOR_RAY_FACTOR * COMPUTE_POOL_MEMORY_MAPPING[ray_worker_instance_family])) + 'G'
            dshm = int(DHSM_MEMORY_FACTOR * COMPUTE_POOL_MEMORY_MAPPING[ray_worker_instance_family])
            if dshm < MIN_DSHM_MEMORY:
                dshm = MIN_DSHM_MEMORY
            dshm_memory_for_ray_worker = str(MIN_DSHM_MEMORY) + 'Gi'
            with file_utils.open_file(ray_worker_spec_file_output_path, "w") as spec_file:
                substitutes = {
                                "ray_worker_container_name": RAY_WORKER_CONTAINER_NAME,
                                "ray_worker_full_image_name": full_image_name_ray_worker,
                                "ray_head_service_name": self.ray_head_service_name,
                                "instance_available_memory_for_ray": instance_available_memory_for_ray_worker,
                                "dshm_memory": dshm_memory_for_ray_worker ,
                                "num_cpu_cores": num_cores,
                                "artifacts_stage": f"@{self.stage_name_for_artifacts}"
                }
                content = string.Template(ray_worker_spec_template).substitute(substitutes)
                content_dict = yaml.safe_load(content)
                if self.ray_worker_compute_pool_type == 'GPU':
                    container = content_dict["spec"]["containers"][0]
                    # TODO[shchen]: SNOW-871538, external dependency that only single GPU is supported on SnowService.
                    # GPU limit has to be specified in order to trigger the workload to be run on GPU in SnowService.
                    container["resources"] = {
                        "limits": {"nvidia.com/gpu": num_worker_gpus},
                        "requests": {"nvidia.com/gpu": num_worker_gpus},
                    }
                yaml.dump(content_dict, spec_file, sort_keys=False)
                logger.debug("Create service spec: \n, %s", content_dict)
            #upload spec for ray worker
            self.session.file.put(
                local_file_name=ray_worker_spec_file_output_path,
                stage_location=f"@{self.stage_name_for_specs}",
                auto_compress=False,
                overwrite=True,
            )
            logger.info(
                f"Uploaded spec file {os.path.basename(ray_worker_spec_file_output_path)} " f"to {self.stage_name_for_specs}"
            )

    def get_compute_pool_properties(self, compute_pool_name:str):
        instance_family = None
        min_nodes = None
        max_nodes = None
        instance_type = None
        compute_pools = self.root.compute_pools.iter(like=f"{compute_pool_name}")
        if len(compute_pools._data)==0:
            logger.info(f"No such compute pool exists: {compute_pool_name}")
        else:
            compute_pool = self.root.compute_pools[compute_pool_name]
            compute_pool_properties = compute_pool.fetch()
            instance_family = compute_pool_properties.instance_family
            min_nodes = compute_pool_properties.min_nodes
            max_nodes = compute_pool_properties.max_nodes
            instance_type = INSTANCE_TYPE_MAPPING[instance_family]
        return [instance_family, min_nodes, max_nodes, instance_type]
        
        
    def get_or_create_compute_pool(self, compute_pool_name, instance_family, min_nodes, max_nodes, service_name, compute_pool_head_or_worker):
        compute_pool = None
        compute_pool_def = ComputePool(
                name=compute_pool_name,
                instance_family=instance_family,
                min_nodes=min_nodes,
                max_nodes=max_nodes
        )
        compute_pools = self.root.compute_pools.iter(like=f"{compute_pool_name}")
        if len(compute_pools._data)==0:
            compute_pool = self.root.compute_pools.create(compute_pool_def)
            logger.info(f"Created compute pool: {compute_pool_name}")
        else:
            compute_pool = self.root.compute_pools[compute_pool_name]
            compute_pool_properties = compute_pool.fetch()
            compute_pool_precreated = False
            if compute_pool_head_or_worker == 'head':
                if self.ray_head_precreated_compute_pool is True:
                    compute_pool_precreated = True
            elif compute_pool_head_or_worker == 'worker':
                if self.ray_worker_precreated_compute_pool is True:
                    compute_pool_precreated = True
            if (compute_pool_precreated) and (compute_pool_properties.instance_family != instance_family or compute_pool_properties.min_nodes != min_nodes or compute_pool_properties.max_nodes != max_nodes):
                raise Exception(f"You have pre-created a compute pool for ray {compute_pool_head_or_worker}. However, either of the the instance_family, min_nodes or max_nodes does not match on the compute pool.")
            if compute_pool_properties.instance_family != instance_family or compute_pool_properties.min_nodes != min_nodes or compute_pool_properties.max_nodes != max_nodes:
                self.delete_service_by_name(service_name)
                compute_pool.delete()
                compute_pool = self.root.compute_pools.create(compute_pool_def)
                logger.info(f"Re-created compute pool: {compute_pool_name}")
            else:
                logger.info(f"Started compute pool: {compute_pool_name}")
        return compute_pool
    
    def get_service_by_name(self, service_name:str):
        service = None
        services = self.root.databases[self.database_name].schemas[self.schema_name].services.iter(like=f"{service_name}")
        if len(services._data)>0:
            service = self.root.databases[self.database_name].schemas[self.schema_name].services[service_name]
        return service
    
    def get_compute_pool_by_name(self, compute_pool_name:str):
        compute_pool = None
        compute_pools = self.root.compute_pools.iter(like=f"{compute_pool_name}")
        if len(compute_pools._data)>0:
            compute_pool = self.root.compute_pools[compute_pool_name]
        return compute_pool
    
    def get_public_endpoints(self):
        ray_head_service = self.get_service_by_name(self.ray_head_service_name)
        if ray_head_service is None:
            raise Exception("Sorry, ray head service does not exist yet. Please create a cluster first")
        return self.get_public_endpoints_by_service_name(self.ray_head_service_name)
    
    def get_public_endpoints_by_service_name(self, service_name:str):
        public_endpoints = []
        rows = self.session.sql(f'SHOW ENDPOINTS IN SERVICE {service_name}').collect()
        ingress_urls = [row['ingress_url'] for row in rows]
        ingress_enabled = [row['is_public'] for row in rows]
        while any(ispublic == 'true' for ispublic in ingress_enabled) and any(url=='Endpoints provisioning in progress... check back in a few minutes' for url in ingress_urls):
            logger.info("Public endpoints not ready, waiting")
            rows = self.session.sql(f'SHOW ENDPOINTS IN SERVICE {service_name}').collect()
            ingress_urls = [row['ingress_url'] for row in rows]
            ingress_enabled = [row['is_public'] for row in rows]
            time.sleep(constants.PUBLIC_ENDPOINTS_WAIT_TIME_SECS)
            continue
        for row in rows:
            if row['is_public'] == 'true':
                endpoint = {}
                endpoint[row['name']] = row['ingress_url']
                public_endpoints.append(endpoint)
        return public_endpoints
    
    def delete_service_by_name(self, service_name):
        service = self.get_service_by_name(service_name)
        if service is not None:
            service.delete()
            logger.info(f"Deleted service: {service_name}")
        
    
    def delete_all_services(self):
        self.delete_service_by_name(self.ray_head_service_name)
        self.delete_service_by_name(self.ray_worker_service_name)
        
    def suspend_all_compute_pools(self):
        self.delete_all_services()
        ray_head_compute_pool = self.get_compute_pool_by_name(compute_pool_name=self.ray_head_compute_pool_name)
        ray_worker_compute_pool = self.get_compute_pool_by_name(compute_pool_name=self.ray_worker_compute_pool_name)
        if ray_head_compute_pool is not None:
            ray_head_compute_pool.suspend()
            logger.info(f"Suspended compute pool: {self.ray_head_compute_pool_name}")
        
        if ray_worker_compute_pool is not None:
            ray_worker_compute_pool.suspend()
            logger.info(f"Suspended compute pool: {self.ray_worker_compute_pool_name}")
        
    def delete_all_compute_pools(self):
        self.delete_all_services()
        ray_head_compute_pool = self.get_compute_pool_by_name(compute_pool_name=self.ray_head_compute_pool_name)
        ray_worker_compute_pool = self.get_compute_pool_by_name(compute_pool_name=self.ray_worker_compute_pool_name)
        if ray_head_compute_pool is not None:
            ray_head_compute_pool.delete()
            logger.info(f"Deleted compute pool: {self.ray_head_compute_pool_name}")
        
        if ray_worker_compute_pool is not None:
            ray_worker_compute_pool.delete()
            logger.info(f"Deleted compute pool: {self.ray_worker_compute_pool_name}")
            
    def delete_ray_image_repository(self):
        _delete_image_repo(self.session, self.image_repo_name)
        
    def get_ray_head_logs(self):
       ray_head_service = self.get_service_by_name(self.ray_head_service_name)
       return ray_head_service.get_service_logs(container_name='head', instance_id=0)
   
    def get_ray_worker_logs(self):
        ray_worker_service = self.get_service_by_name(self.ray_worker_service_name)
        return ray_worker_service.get_service_logs(container_name='worker', instance_id=0)
    
    def get_ray_head_service_status(self):
        ray_head_service = self.get_service_by_name(self.ray_head_service_name)
        return ray_head_service.get_service_status(timeout=0)
    
    def get_ray_worker_service_status(self):
        ray_worker_service = self.get_service_by_name(self.ray_worker_service_name)
        return ray_worker_service.get_service_status(timeout=0)
    
    