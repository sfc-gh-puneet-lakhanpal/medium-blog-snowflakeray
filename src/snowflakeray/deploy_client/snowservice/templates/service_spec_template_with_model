spec:
  container:
    - name: ${inference_server_container_name}
      image: ${image}
      env:
        TARGET_METHOD: ${target_method}
        NUM_WORKERS: ${num_workers}
        SNOWML_USE_GPU: ${use_gpu}
      readinessProbe:
        port: 5000
        path: /health
      volumeMounts:
        - name: vol1
          mountPath: /local/user/vol1
  endpoint:
    - name: ${predict_endpoint_name}
      port: 5000
      public: ${enable_ingress}
  volume:
    - name: vol1
      source: local  # only local emptyDir volume is supported
